/*
 * Copyright 2024 CloudWeGo Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

// Package model defines callback payloads and configuration types for chat models.
package model

import (
	"github.com/cloudwego/eino/callbacks"
	"github.com/cloudwego/eino/schema"
)

// TokenUsage is the token usage for the model.
//
// TokenUsage 是模型的 token 使用情况。
type TokenUsage struct {
	// PromptTokens is the number of prompt tokens, including all the input tokens of this request.
	// PromptTokens 是 prompt token 的数量，包括此请求的所有输入 token。
	PromptTokens int
	// PromptTokenDetails is a breakdown of the prompt tokens.
	// PromptTokenDetails 是 prompt token 的细分。
	PromptTokenDetails PromptTokenDetails
	// CompletionTokens is the number of completion tokens.
	// CompletionTokens 是 completion token 的数量。
	CompletionTokens int
	// TotalTokens is the total number of tokens.
	// TotalTokens 是 token 的总数。
	TotalTokens int
	// CompletionTokensDetails is breakdown of completion tokens.
	// CompletionTokensDetails 是 completion token 的细分。
	CompletionTokensDetails CompletionTokensDetails `json:"completion_token_details"`
}

type CompletionTokensDetails struct {
	// ReasoningTokens tokens generated by the model for reasoning.
	// This is currently supported by OpenAI, Gemini, ARK and Qwen  chat models.
	// For other models, this field will be 0.
	//
	// ReasoningTokens 模型用于推理生成的 token。
	// 目前支持 OpenAI, Gemini, ARK 和 Qwen 聊天模型。
	// 对于其他模型，此字段将为 0。
	ReasoningTokens int `json:"reasoning_tokens,omitempty"`
}

// PromptTokenDetails provides a breakdown of prompt token usage.
//
// PromptTokenDetails 提供 prompt token 使用情况的细分。
type PromptTokenDetails struct {
	// Cached tokens present in the prompt.
	// CachedTokens 是 prompt 中存在的缓存 token。
	CachedTokens int
}

// Config is the config for the model.
//
// Config 是模型的配置。
type Config struct {
	// Model is the model name.
	// Model 是模型名称。
	Model string
	// MaxTokens is the max number of tokens, if reached the max tokens, the model will stop generating, and mostly return an finish reason of "length".
	// MaxTokens 是最大 token 数，如果达到最大 token 数，模型将停止生成，并且通常返回 "length" 的结束原因。
	MaxTokens int
	// Temperature is the temperature, which controls the randomness of the model.
	// Temperature 是温度，控制模型的随机性。
	Temperature float32
	// TopP is the top p, which controls the diversity of the model.
	// TopP 是 top p，控制模型的多样性。
	TopP float32
	// Stop is the stop words, which controls the stopping condition of the model.
	// Stop 是停止词，控制模型的停止条件。
	Stop []string
}

// CallbackInput is the input for the model callback.
//
// CallbackInput 是模型回调的输入。
type CallbackInput struct {
	// Messages is the messages to be sent to the model.
	// Messages 是发送给模型的消息。
	Messages []*schema.Message
	// Tools is the tools to be used in the model.
	// Tools 是模型要使用的工具。
	Tools []*schema.ToolInfo
	// ToolChoice is the tool choice, which controls the tool to be used in the model.
	// ToolChoice 是工具选择，控制模型要使用的工具。
	ToolChoice *schema.ToolChoice
	// Config is the config for the model.
	// Config 是模型的配置。
	Config *Config
	// Extra is the extra information for the callback.
	// Extra 是回调的额外信息。
	Extra map[string]any
}

// CallbackOutput is the output for the model callback.
//
// CallbackOutput 是模型回调的输出。
type CallbackOutput struct {
	// Message is the message generated by the model.
	// Message 是模型生成的消息。
	Message *schema.Message
	// Config is the config for the model.
	// Config 是模型的配置。
	Config *Config
	// TokenUsage is the token usage of this request.
	// TokenUsage 是此请求的 token 使用情况。
	TokenUsage *TokenUsage
	// Extra is the extra information for the callback.
	// Extra 是回调的额外信息。
	Extra map[string]any
}

// ConvCallbackInput converts the callback input to the model callback input.
//
// ConvCallbackInput 将回调输入转换为模型回调输入。
func ConvCallbackInput(src callbacks.CallbackInput) *CallbackInput {
	switch t := src.(type) {
	case *CallbackInput: // when callback is triggered within component implementation, the input is usually already a typed *model.CallbackInput
		return t
	case []*schema.Message: // when callback is injected by graph node, not the component implementation itself, the input is the input of Chat Model interface, which is []*schema.Message
		return &CallbackInput{
			Messages: t,
		}
	default:
		return nil
	}
}

// ConvCallbackOutput converts the callback output to the model callback output.
func ConvCallbackOutput(src callbacks.CallbackOutput) *CallbackOutput {
	switch t := src.(type) {
	case *CallbackOutput: // when callback is triggered within component implementation, the output is usually already a typed *model.CallbackOutput
		return t
	case *schema.Message: // when callback is injected by graph node, not the component implementation itself, the output is the output of Chat Model interface, which is *schema.Message
		return &CallbackOutput{
			Message: t,
		}
	default:
		return nil
	}
}
